import requests
import pandas as pd
import xml.etree.ElementTree as ET
import os
from datetime import datetime, timedelta
import time
import random

# –°–ª–æ–≤–∞—Ä—å —Ç–∏–∫–µ—Ä–æ–≤: —Ç–∏–∫–µ—Ä -> (–¥–∞—Ç–∞_–Ω–∞—á–∞–ª–∞, —Ç–∏–ø_–∞–∫—Ç–∏–≤–∞, –±–æ—Ä–¥)
TICKERS = {
    "LQDT":  ("2022-01-01", "fund", "TQTF"),
    "GOLD":  ("2022-07-01", "fund", "TQTF"),
    "OBLG":  ("2022-12-09", "fund", "TQTF"),
    "EQMX":  ("2022-01-01", "fund", "TQTF"),
    "RVI":   ("2022-01-01", "index", "RTSI"),
    "IMOEX": ("2022-01-01", "index", "SNDX")  # –ò–Ω–¥–µ–∫—Å –ú–æ—Å–ë–∏—Ä–∂–∏
}

DATA_DIR = "data"
os.makedirs(DATA_DIR, exist_ok=True)

MAX_RETRIES = 5

# ============================================
# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–µ—Å—Å–∏–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –∑–∞—â–∏—Ç—ã –ú–æ—Å–±–∏—Ä–∂–∏
# ============================================
session = requests.Session()
session.headers.update({
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'ru-RU,ru;q=0.9,en;q=0.8',
    'Accept-Encoding': 'gzip, deflate',
    'Connection': 'keep-alive',
    'Cache-Control': 'max-age=0',
})


def fetch_moex_history_paginated(ticker, date_from, date_till, asset_type="fund", board="TQTF"):
    all_rows = []
    start = 0

    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π URL –ë–ï–ó –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
    if asset_type == "index":
        base_url = f"https://iss.moex.com/iss/history/engines/stock/markets/index/boards/{board}/securities/{ticker}.xml"
    else:
        base_url = f"https://iss.moex.com/iss/history/engines/stock/markets/shares/boards/{board}/securities/{ticker}.xml"

    while True:
        url = f"{base_url}?from={date_from}&till={date_till}&start={start}"
        print(f"üîπ –ó–∞–ø—Ä–æ—Å: {url}")

        for attempt in range(1, MAX_RETRIES + 1):
            try:
                # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
                if attempt > 1:
                    delay = min(2 ** (attempt - 1) + random.uniform(0, 1), 10)
                    print(f"  ‚è≥ –ü–∞—É–∑–∞ {delay:.1f} —Å–µ–∫ –ø–µ—Ä–µ–¥ –ø–æ–ø—ã—Ç–∫–æ–π {attempt}")
                    time.sleep(delay)

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ—Å—Å–∏—é –≤–º–µ—Å—Ç–æ requests.get()
                r = session.get(url, timeout=(30, 60))  # connect=30s, read=60s
                r.raise_for_status()
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –∏–ª–∏ –æ—à–∏–±–∫—É –≤ XML
                if not r.text.strip():
                    raise Exception("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞")
                if "<error>" in r.text.lower():
                    raise Exception(f"–û—à–∏–±–∫–∞ –≤ –æ—Ç–≤–µ—Ç–µ: {r.text[:300]}")
                
                root = ET.fromstring(r.text)
                break
                
            except requests.exceptions.Timeout as e:
                print(f"‚ö† –¢–∞–π–º–∞—É—Ç (–ø–æ–ø—ã—Ç–∫–∞ {attempt}/{MAX_RETRIES}): {e}")
                if attempt == MAX_RETRIES:
                    print(f"‚ùå –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {ticker} (start={start}) –ø–æ—Å–ª–µ {MAX_RETRIES} –ø–æ–ø—ã—Ç–æ–∫")
                    return pd.DataFrame()
                    
            except requests.exceptions.RequestException as e:
                print(f"‚ö† –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt}/{MAX_RETRIES}): {e}")
                if attempt == MAX_RETRIES:
                    print(f"‚ùå –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {ticker} (start={start}) –ø–æ—Å–ª–µ {MAX_RETRIES} –ø–æ–ø—ã—Ç–æ–∫")
                    return pd.DataFrame()
                    
            except Exception as e:
                print(f"‚ö† –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt}/{MAX_RETRIES}): {e}")
                if attempt == MAX_RETRIES:
                    print(f"‚ùå –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {ticker} (start={start}) –ø–æ—Å–ª–µ {MAX_RETRIES} –ø–æ–ø—ã—Ç–æ–∫")
                    return pd.DataFrame()

        rows = root.findall(".//row")
        row_count = len(rows)

        if row_count == 0:
            break

        for row in rows:
            all_rows.append(row.attrib)

        print(f"  –ü–æ–ª—É—á–µ–Ω–æ {row_count} —Å—Ç—Ä–æ–∫ (start={start})")

        if row_count < 100:
            break

        start += 100
        # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏ –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è —Ä–µ–π—Ç-–ª–∏–º–∏—Ç–æ–≤
        time.sleep(0.5 + random.uniform(0, 0.5))

    if not all_rows:
        return pd.DataFrame()
    
    df = pd.DataFrame(all_rows)
    required_cols = ["TRADEDATE", "OPEN", "HIGH", "LOW", "CLOSE"]
    
    # –î–æ–±–∞–≤–ª—è–µ–º VOLUME –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –∑–∞–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏
    if "VOLUME" not in df.columns:
        df["VOLUME"] = 0
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ —á–∏—Å–ª–æ–≤—ã—Ö –ø–æ–ª—è—Ö
    for col in ["OPEN", "HIGH", "LOW", "CLOSE", "VOLUME"]:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    cols = [col for col in required_cols + ["VOLUME"] if col in df.columns]
    df = df[cols]
    df['TRADEDATE'] = pd.to_datetime(df['TRADEDATE'])
    return df.sort_values("TRADEDATE").reset_index(drop=True)


def update_ticker(ticker, start_date, asset_type, board):
    file_path = os.path.join(DATA_DIR, f"{ticker}.csv")

    if os.path.exists(file_path):
        df_old = pd.read_csv(file_path)
        df_old['TRADEDATE'] = pd.to_datetime(df_old['TRADEDATE'])
        last_date = (df_old['TRADEDATE'].max() + timedelta(days=1)).strftime("%Y-%m-%d")
        print(f"üìÖ –ü–æ—Å–ª–µ–¥–Ω—è—è –¥–∞—Ç–∞ –≤ {file_path}: {last_date} (–∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Å —ç—Ç–æ–π –¥–∞—Ç—ã)")
    else:
        df_old = pd.DataFrame()
        last_date = start_date
        print(f"üÜï –§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –Ω–∞—á–∏–Ω–∞–µ–º —Å {start_date}")

    today = datetime.today().strftime("%Y-%m-%d")
    df_new = fetch_moex_history_paginated(ticker, last_date, today, asset_type, board)

    if df_new.empty:
        print(f"‚ö† –ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {ticker}")
        return

    if not df_old.empty:
        df_full = pd.concat([df_old, df_new]).drop_duplicates(subset="TRADEDATE").sort_values("TRADEDATE")
    else:
        df_full = df_new

    df_full.to_csv(file_path, index=False)
    print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ: {file_path} ‚Äî {len(df_new)} –Ω–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫ (–≤—Å–µ–≥–æ {len(df_full)})")


if __name__ == "__main__":
    print(f"üöÄ –ó–∞–ø—É—Å–∫ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"üåê –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ—Å—Å–∏—é —Å –±—Ä–∞—É–∑–µ—Ä–Ω—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –∑–∞—â–∏—Ç—ã –ú–æ—Å–±–∏—Ä–∂–∏\n")
    
    for ticker, (start_date, asset_type, board) in TICKERS.items():
        print(f"\n{'='*60}")
        print(f"=== –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {ticker} ({asset_type}, board={board}) ===")
        print(f"{'='*60}")
        update_ticker(ticker, start_date, asset_type, board)
        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–∏–∫–µ—Ä–∞–º–∏ –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è —Ä–µ–π—Ç-–ª–∏–º–∏—Ç–æ–≤
        if ticker != list(TICKERS.keys())[-1]:
            delay = 1.5 + random.uniform(0, 0.5)
            print(f"‚è≥ –ü–∞—É–∑–∞ {delay:.1f} —Å–µ–∫ –º–µ–∂–¥—É —Ç–∏–∫–µ—Ä–∞–º–∏...")
            time.sleep(delay)
    
    print(f"\nüèÅ –ó–∞–≤–µ—Ä—à–µ–Ω–æ –≤ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    session.close()  # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–µ—Å—Å–∏—é
