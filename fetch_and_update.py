import requests
import pandas as pd
import xml.etree.ElementTree as ET
import os
from datetime import datetime
import time

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–∏–∫–µ—Ä–æ–≤ ---
TICKERS = {
    "LQDT": "2022-01-01",
    "GOLD": "2022-01-01",
    "OBLG": "2022-12-09",
    "EQMX": "2022-01-01"
}

DATA_DIR = "data"
os.makedirs(DATA_DIR, exist_ok=True)

MAX_RETRIES = 5
RETRY_DELAY = 5  # —Å–µ–∫—É–Ω–¥ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏

def fetch_moex_history_paginated(ticker, date_from, date_till):
    all_rows = []
    start = 0

    while True:
        url = (f"https://iss.moex.com/iss/history/engines/stock/markets/shares/boards/TQTF/"
               f"securities/{ticker}.xml?from={date_from}&till={date_till}&start={start}")
        print(f"üîπ –ó–∞–ø—Ä–æ—Å: {url}")

        for attempt in range(1, MAX_RETRIES + 1):
            try:
                r = requests.get(url, timeout=10)
                if r.status_code != 200:
                    raise Exception(f"HTTP {r.status_code}")
                root = ET.fromstring(r.text)
                break
            except Exception as e:
                print(f"‚ö† –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞/–ø–∞—Ä—Å–∏–Ω–≥–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt}/{MAX_RETRIES}): {e}")
                if attempt < MAX_RETRIES:
                    time.sleep(RETRY_DELAY)
                else:
                    print(f"‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω–æ —á–∏—Å–ª–æ –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è {ticker}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º batch start={start}")
                    return pd.DataFrame()

        rows = root.findall(".//row")
        if not rows:
            break

        for row in rows:
            all_rows.append(row.attrib)

        print(f"  –ü–æ–ª—É—á–µ–Ω–æ {len(rows)} —Å—Ç—Ä–æ–∫ (start={start})")
        start += 100

    if not all_rows:
        return pd.DataFrame()
    
    df = pd.DataFrame(all_rows)
    columns = ["TRADEDATE", "OPEN", "HIGH", "LOW", "CLOSE", "VOLUME"]
    df = df[columns]
    df['TRADEDATE'] = pd.to_datetime(df['TRADEDATE'])
    return df

def update_ticker(ticker, start_date):
    file_path = os.path.join(DATA_DIR, f"{ticker}.csv")

    if os.path.exists(file_path):
        df_old = pd.read_csv(file_path)
        df_old['TRADEDATE'] = pd.to_datetime(df_old['TRADEDATE'])
        last_date = df_old['TRADEDATE'].max().strftime("%Y-%m-%d")
        print(f"üìÖ –ü–æ—Å–ª–µ–¥–Ω—è—è –¥–∞—Ç–∞ –≤ {file_path}: {last_date}")
    else:
        df_old = pd.DataFrame()
        last_date = start_date

    today = datetime.today().strftime("%Y-%m-%d")
    df_new = fetch_moex_history_paginated(ticker, last_date, today)

    if df_new.empty:
        print(f"‚ö† –ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {ticker}")
        return

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç–∞—Ä—ã–µ –∏ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    if not df_old.empty:
        df_full = pd.concat([df_old, df_new]).drop_duplicates(subset="TRADEDATE").sort_values("TRADEDATE")
    else:
        df_full = df_new.sort_values("TRADEDATE")

    df_full.to_csv(file_path, index=False)
    print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ: {file_path} ‚Äî {len(df_new)} –Ω–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫, –≤—Å–µ–≥–æ {len(df_full)} —Å—Ç—Ä–æ–∫")

# === –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª ===
if __name__ == "__main__":
    for ticker, start_date in TICKERS.items():
        print(f"\n=== –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {ticker} ===")
        update_ticker(ticker, start_date)
